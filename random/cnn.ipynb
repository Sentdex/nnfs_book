{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "from activation_func.relu import Activation_ReLU\n",
    "from layers.layer_dense import Layer_Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max pooling over batch of images\n",
    "def max_pool(inputs,f,stride):\n",
    "    #get shapes\n",
    "    (m,n_h_prev,n_w_prev,n_c_prev)=inputs.shape\n",
    "    \n",
    "    #define output shape\n",
    "    n_h=int((n_h_prev-f)/stride)+1\n",
    "    n_w=int((n_w_prev-f)/stride)+1\n",
    "    \n",
    "    #output\n",
    "    output=np.zeros((m,n_h,n_w,n_c_prev))\n",
    "\n",
    "    for i in range(m):\n",
    "        inputi=inputs[i]\n",
    "        for h in range(n_h):\n",
    "            for w in range(n_w):\n",
    "                for c in range(n_c_prev):\n",
    "                    #define vert/horiz start-end  \n",
    "                    vert_start=h*stride\n",
    "                    vert_end=vert_start+f\n",
    "                    horiz_start=w*stride\n",
    "                    horiz_end=horiz_start+f\n",
    "                    #get image slice \n",
    "                    inputi_slice=inputi[vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                    #max pooling on inputs[i] slice\n",
    "                    output[i,h,w,c]=np.max(inputi_slice)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of inputs before max-pool  (3, 15, 15, 3)\n",
      "shape of inputs after max-pool  (3, 7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "inputs=np.random.rand(3,15,15,3)\n",
    "#hyperparameters shrinking by a factor of 2 \n",
    "f=2\n",
    "stride=2\n",
    "output=max_pool(inputs,f,stride)\n",
    "\n",
    "print('shape of inputs before max-pool ',inputs.shape)\n",
    "print('shape of inputs after max-pool ',output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_forward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-554d6254f8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpadding1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#forward pass layer1(convolution + relu + max pooling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mconv1_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mrelu1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmax_pool1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_forward' is not defined"
     ]
    }
   ],
   "source": [
    "#CNN example forward pass ||something similar to LeNet-5  \n",
    "inputs=np.random.rand(5,32,32,3)\n",
    "\n",
    "#layer1 \n",
    "relu1=Activation_ReLU()\n",
    "w1=np.random.rand(5,5,3,6)\n",
    "b1=np.random.rand(1,1,1,6)\n",
    "stride1=1\n",
    "padding1=0\n",
    "#forward pass layer1(convolution + relu + max pooling)\n",
    "conv1_out=conv_forward(inputs,w1,b1,padding1,stride1)\n",
    "relu1.forward(conv1_out,training=True)\n",
    "max_pool1=max_pool(relu1.output,f=2,stride=2)\n",
    "\n",
    "#layer2\n",
    "relu2=Activation_ReLU()\n",
    "w2=np.random.rand(5,5,6,16)\n",
    "b2=np.random.rand(1,1,1,16)\n",
    "stride2=1\n",
    "padding2=0\n",
    "#forward pass layer2(conv,relu,max-pool)\n",
    "conv2_out=conv_forward(max_pool1,w2,b2,padding2,stride2)\n",
    "relu2.forward(conv2_out,training=True)\n",
    "max_pool2=max_pool(relu2.output,f=2,stride=2)\n",
    "\n",
    "\n",
    "#flatten/reshape the max-pool2\n",
    "x=max_pool2.reshape(max_pool2.shape[0],-1)\n",
    "\n",
    "#fully-connected layer3\n",
    "layer3=Layer_Dense(400,120)\n",
    "relu3=Activation_ReLU()\n",
    "#forward pass layer3(linear-layer,relu)\n",
    "layer3.forward(x,training=True)\n",
    "relu3.forward(layer3.output,training=True)\n",
    "\n",
    "#fully-connected layer4\n",
    "layer4=Layer_Dense(120,84)\n",
    "relu4=Activation_ReLU()\n",
    "layer4.forward(relu3.output,training=True)\n",
    "relu4.forward(layer4.output,training=True)\n",
    "\n",
    "#fully-connected layer5\n",
    "layer5=Layer_Dense(84,10)\n",
    "relu5=Activation_ReLU()\n",
    "layer5.forward(relu4.output,training=True)\n",
    "relu5.forward(layer5.output,training=True)\n",
    "\n",
    "\n",
    "#softmax probability distribution \n",
    "softmax=Activation_Softmax()\n",
    "softmax.forward(relu5.output,training=True)\n",
    "\n",
    "print('shape of inputs',inputs.shape)\n",
    "print('shape of 1st layer max-out',max_pool1.shape) \n",
    "print('shape of 2st layer max-out',max_pool2.shape)\n",
    "print('shape of inputs flattened',x.shape)\n",
    "print('shape of 3st fc relu',relu3.output.shape)\n",
    "print('shape of 4th fc relu out',relu4.output.shape)\n",
    "print('shape of 5th fc relu out',relu5.output.shape)\n",
    "print('final softmax shape',softmax.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input=torch.rand(1,1,3,3)\n",
    "m=nn.Conv2d(1,2,[2,2],bias=True,padding=2,padding_mode='zeros',stride=2)\n",
    "m.requires_grad_=True\n",
    "\n",
    "out=m(input)\n",
    "\n",
    "t=out.sum()\n",
    "\n",
    "t.backward()\n",
    "\n",
    "t_weights_grad=m.weight.grad.permute(2,3,1,0).numpy()[:,:,0,:]\n",
    "t_bias=m.bias.grad\n",
    "t_out=out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding2d(inputs,padding):\n",
    "    inputs_padded = np.pad(inputs, ((0,0), (padding,padding), (padding,padding),\n",
    "                            ), mode='constant', constant_values = (0,0))\n",
    "    return inputs_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw grad  [[[2.7379756  2.7379756 ]\n",
      "  [0.53760237 0.53760237]]\n",
      "\n",
      " [[1.1505195  1.1505195 ]\n",
      "  [0.59693444 0.59693444]]]\n",
      "db grad  [9. 9.]\n"
     ]
    }
   ],
   "source": [
    "#simple 2d convolution forward/backward pass  without biases  \n",
    "inputs=input.permute(0,2,3,1).numpy()[:,:,:,0]\n",
    "#permute the shapes to match [fh,fw,n_c_out] \n",
    "weights=m.weight.permute(2,3,1,0).detach().numpy()[:,:,0,:]\n",
    "bias=m.bias.detach().numpy()\n",
    "pad=2\n",
    "stride=2\n",
    "\n",
    "\n",
    "(m,n_h_prev,n_w_prev)=inputs.shape\n",
    "(f_h,f_w,n_c)=weights.shape\n",
    "\n",
    "n_h=int((n_h_prev-f_h+2*pad)/stride)+1\n",
    "n_w=int((n_w_prev-f_w+2*pad)/stride)+1\n",
    "\n",
    "output=np.zeros((m,n_h,n_w,n_c))\n",
    "\n",
    "input_pad=zero_padding2d(inputs,pad)\n",
    "\n",
    "#forward pass works \n",
    "for i in range(m):\n",
    "    inputi=input_pad[i]\n",
    "    for h in range(n_h):\n",
    "        for w in range(n_w):\n",
    "            for c in range(n_c):\n",
    "                vert_start=h*stride\n",
    "                vert_end=vert_start+f_h\n",
    "                horiz_start=w*stride\n",
    "                horiz_end=horiz_start+f_w\n",
    "\n",
    "                input_slice=inputi[vert_start:vert_end,horiz_start:horiz_end]\n",
    "                output[i,h,w,c]=np.sum(np.multiply(input_slice,weights[:,:,c]))+bias[c]\n",
    "\n",
    "#backward pass \n",
    "dinputs=np.ones_like(output)\n",
    "dw=np.zeros_like(weights)\n",
    "db=np.sum(dinputs,axis=(0,1,2))\n",
    "\n",
    "for i in range(m):\n",
    "    inputi=input_pad[i]\n",
    "    for h in range(n_h):\n",
    "        for w in range(n_w):\n",
    "            for c in range(n_c):\n",
    "                vert_start=h*stride\n",
    "                vert_end=vert_start+f_h\n",
    "                horiz_start=w*stride\n",
    "                horiz_end=horiz_start+f_w\n",
    "                input_slice=inputi[vert_start:vert_end,horiz_start:horiz_end]\n",
    "                dw[:,:,c]+=np.multiply(input_slice,dinputs[i,h,w,c])\n",
    "\n",
    "#bias in this implementation expects batch of images \n",
    "print('dw grad ',dw)\n",
    "print('db grad ',db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc(values, decs=0):\n",
    "    return np.trunc(values*10**decs)/(10**decs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[False, False],\n",
       "         [False, False],\n",
       "         [False, False]],\n",
       "\n",
       "        [[False, False],\n",
       "         [False, False],\n",
       "         [False, False]],\n",
       "\n",
       "        [[False, False],\n",
       "         [False, False],\n",
       "         [False, False]]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(trunc(t_out.permute(0,2,3,1).detach().numpy(),3),trunc(output,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3)\n",
      "output compare True\n",
      "dweights compare True\n",
      "dbiases compare True\n"
     ]
    }
   ],
   "source": [
    "from convolution.conv_2d import Conv2D\n",
    "\n",
    "conv2d=Conv2D([1],1,padding=2,stride=2)\n",
    "conv2d.set_params(weights,bias)\n",
    "\n",
    "print(inputs.shape)\n",
    "conv2d.forward(inputs)\n",
    "\n",
    "\n",
    "conv2d.backward(dinputs)\n",
    "#compare to numpy results above \n",
    "print('output compare',(output==conv2d.output).all())\n",
    "print('dweights compare',(conv2d.dweights==dw).all())\n",
    "print('dbiases compare',(conv2d.dbiases==db).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc(values, decs=0):\n",
    "    return np.trunc(values*10**decs)/(10**decs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ef2008c9aec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt_dw_trunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_weights_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv_dw_trun\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mt_dw_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbiases\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mt_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "conv_dw_trun=trunc(conv2d.dweights,3)\n",
    "t_dw_trunc=trunc(t_weights_grad,3)\n",
    "(conv_dw_trun==t_dw_trunc).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare\n",
    "dw_trunc=trunc(dw,3)\n",
    "torch_dw_trunc=trunc(t_weights_grad,3)\n",
    "#compare values \n",
    "(dw_trunc==torch_dw_trunc).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
